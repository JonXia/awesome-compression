{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入相关库和网络\n",
    "\n",
    "使用 `res32x4` 去蒸馏 `res8x4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/terry/miniconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/terry/miniconda3/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <2BD1B165-EC09-3F68-BCE4-8FE4E70CA7E2> /Users/terry/miniconda3/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <D400622C-0C6B-3AE1-AB45-F1D0BF19B384> /Users/terry/miniconda3/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "\n",
    "# 知识蒸馏 KD 的损失函数\n",
    "from loss.kd import loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机数种子, 从而可以复现\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "setup_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 4               # temperature : 知识蒸馏中的温度\n",
    "ALPHA = 0.1         # alpha : hard_loss(硬损失交叉熵)的loss weight \n",
    "BETA = 0.9          # beta : soft_loss(软损失KL散度)的loss weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载教师模型, 以及定义学生网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(in_features=16 * 4 * 4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.fc3 = nn.Linear(in_features=84, out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.maxpool(F.relu(self.conv1(x)))\n",
    "        x = self.maxpool(F.relu(self.conv2(x)))\n",
    "\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class LeNetHalfChannel(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LeNetHalfChannel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=5)   \n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(in_features=3 * 12 * 12, out_features=10)   \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.maxpool(F.relu(self.conv1(x)))\n",
    "\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "teacher_net = LeNet().to(device=device)\n",
    "student_net = LeNetHalfChannel().to(device=device)\n",
    "\n",
    "teacher_net.load_state_dict(torch.load('../ch02/model.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据集\n",
    "第一次使用会先进行下载, 如果下载的很慢, 可以手动下载数据集然后拖入到 data 文件夹下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置归一化\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "# 获取数据集\n",
    "# 这里直接读取 ch02 中下载好的数据\n",
    "train_dataset = datasets.MNIST(root='../ch02/data/mnist/', train=True, download=False, transform=transform)  \n",
    "test_dataset = datasets.MNIST(root='../ch02/data/mnist/', train=False, download=False, transform=transform)  # train=True训练集，=False测试集\n",
    "\n",
    "# 设置DataLoader\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "momentum = 0.5\n",
    "num_epoch = 5\n",
    "optimizer = torch.optim.SGD(student_net.parameters(),  lr=lr, momentum=momentum)  # lr学习率，momentum冲量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train函数和Test函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分别定义训练集和测试集上的最佳Acc, 使用 global 修饰为全局变量, 然后再训练期间更新\n",
    "best_train_acc = 0\n",
    "best_test_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(epoch):\n",
    "    global best_train_acc\n",
    "\n",
    "    # 设置学生模型为训练模式\n",
    "    student_net.train()\n",
    "\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # 使用 tqdm 包装 trainloader 以显示进度条\n",
    "    with tqdm(train_loader, desc=f\"Training Epoch {epoch}\", total=len(train_loader)) as pbar:\n",
    "        for batch_idx, (inputs, targets) in enumerate(pbar):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logits_student = student_net(inputs)\n",
    "            with torch.no_grad():\n",
    "                logits_teacher = teacher_net(inputs)\n",
    "\n",
    "            # 硬损失\n",
    "            ce_loss = nn.CrossEntropyLoss()(logits_student, targets)\n",
    "            # 软损失\n",
    "            kd_loss = loss(logits_student, logits_teacher, temperature=T)\n",
    "            total_loss = ALPHA * ce_loss + BETA * kd_loss\n",
    "\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += total_loss.item()\n",
    "            _, predicted = logits_student.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            # 使用 set_postfix 更新进度条的后缀\n",
    "            pbar.set_postfix(loss=train_loss / (batch_idx + 1), acc=f\"{100. * correct / total:.1f}%\")\n",
    "\n",
    "    # 如果当前训练集上的准确率高于 best_test_acc，则更新 best_test_acc\n",
    "    acc = 100 * correct / total\n",
    "    if acc > best_train_acc:\n",
    "        best_train_acc = acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, epoch):\n",
    "    global best_test_acc\n",
    "    net.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # 使用 tqdm 包装 testloader 以显示进度条\n",
    "        with tqdm(test_loader, desc=f\"Testing Epoch {epoch}\", total=len(test_loader)) as pbar:\n",
    "            for batch_idx, (inputs, targets) in enumerate(pbar):\n",
    "\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                logits_student = net(inputs)\n",
    "\n",
    "                loss = nn.CrossEntropyLoss()(logits_student, targets)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = logits_student.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "                # 在 tqdm 进度条的后缀中显示当前损失和准确率\n",
    "                pbar.set_postfix(loss=test_loss / (batch_idx + 1), acc=f\"{100. * correct / total:.1f}%\")\n",
    "\n",
    "        # 计算当前测试集上的准确率\n",
    "        acc = 100. * correct / total\n",
    "\n",
    "        # 如果当前测试集上的准确率高于 best_test_acc，则更新 best_test_acc\n",
    "        # 并且将学生模型保存下来\n",
    "        if acc > best_test_acc:\n",
    "            print('Saving..')\n",
    "            torch.save(student_net, 'checkpoints/distillation_kd.pt')\n",
    "            best_test_acc = acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:   0%|          | 0/938 [00:00<?, ?it/s, acc=9.4%, loss=14.2]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 938/938 [00:16<00:00, 58.15it/s, acc=76.4%, loss=3.58]\n",
      "Testing Epoch 1: 100%|██████████| 157/157 [00:01<00:00, 116.71it/s, acc=95.6%, loss=0.14] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 938/938 [00:19<00:00, 49.07it/s, acc=95.5%, loss=0.639]\n",
      "Testing Epoch 2: 100%|██████████| 157/157 [00:01<00:00, 108.94it/s, acc=96.5%, loss=0.111]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 938/938 [00:12<00:00, 72.31it/s, acc=96.1%, loss=0.529]\n",
      "Testing Epoch 3: 100%|██████████| 157/157 [00:00<00:00, 158.06it/s, acc=96.4%, loss=0.111]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████| 938/938 [00:12<00:00, 76.12it/s, acc=96.4%, loss=0.496]\n",
      "Testing Epoch 4: 100%|██████████| 157/157 [00:00<00:00, 171.95it/s, acc=96.8%, loss=0.102] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████| 938/938 [00:11<00:00, 82.18it/s, acc=96.3%, loss=0.482]\n",
      "Testing Epoch 5: 100%|██████████| 157/157 [00:00<00:00, 169.48it/s, acc=96.7%, loss=0.103]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, num_epoch + 1) :\n",
    "    train(epoch)\n",
    "    test(student_net, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_Train_Acc =  96.39\n",
      "best_Test_Acc =  96.85\n"
     ]
    }
   ],
   "source": [
    "print('best_Train_Acc = ', best_train_acc)\n",
    "print('best_Test_Acc = ', best_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
